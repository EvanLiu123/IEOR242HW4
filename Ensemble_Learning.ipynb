{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evanliu/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pylab\n",
    "import calendar\n",
    "import seaborn as sn\n",
    "import missingno as msno\n",
    "from datetime import datetime\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  #\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剔除训练数据中的极端值后，将其特征矩阵和测试数据中的特征矩阵合并，维度为: (355471, 8)\n"
     ]
    }
   ],
   "source": [
    "dailyData = pd.read_csv(\"train.csv\")\n",
    "dailyDataTest = pd.read_csv(\"test.csv\")\n",
    "dailyData.drop(['row_id'], axis=1, inplace=True)\n",
    "dailyDataTest.drop(['row_id'], axis=1, inplace=True)\n",
    "\n",
    "# convert negative trip_distance to positive values\n",
    "for index in dailyData.index:\n",
    "    if dailyData['trip_distance'][index]<0:\n",
    "        dailyData['trip_distance'][index] = -dailyData['trip_distance'][index]\n",
    "# convert negative trip_distance to positive values\n",
    "for index in dailyDataTest.index:\n",
    "    if dailyDataTest['trip_distance'][index]<0:\n",
    "        dailyDataTest['trip_distance'][index] = -dailyDataTest['trip_distance'][index]\n",
    "\n",
    "# remove all data with trip_distance=0\n",
    "dailyData = dailyData.query('trip_distance > 0.1')\n",
    "# top speed for taxi 36s/mile\n",
    "dailyData = dailyData.query('duration >= trip_distance*36')\n",
    "# speed on foot 1200s/mile\n",
    "dailyData1 = dailyData.query('duration <= trip_distance*1200')\n",
    "# include some severe traffic jam and short trip distance\n",
    "dailyData2 = dailyData.query('duration > trip_distance*1200 and trip_distance < 10 and duration < 7200')\n",
    "dailyData = dailyData1.append(dailyData2)\n",
    "dailyData.reset_index(inplace=True)\n",
    "dailyData.drop('index',inplace=True,axis=1)\n",
    "#remove outliers\n",
    "# dailyData = dailyData.query('duration < 10000')\n",
    "\n",
    "dailyData['duration']=np.log1p(dailyData['duration'])\n",
    "y = dailyData['duration'].reset_index(drop=True) \n",
    "train_features = dailyData.drop(['duration'],axis=1)\n",
    "test_features = dailyDataTest\n",
    "features = pd.concat([train_features, test_features]).reset_index(drop=True)\n",
    "print(\"剔除训练数据中的极端值后，将其特征矩阵和测试数据中的特征矩阵合并，维度为:\",features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID           float64\n",
       "pickup_datetime     object\n",
       "passenger_count    float64\n",
       "trip_distance      float64\n",
       "pickup_borough      object\n",
       "pickup_zone         object\n",
       "dropoff_borough     object\n",
       "dropoff_zone        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan with 2019-03-31 00:00:00 in datetime\n",
    "dailyData = dailyData.rename(columns={'pickup_datetime':'datetime'})\n",
    "dailyData['datetime'].fillna(\"2019-03-31 00:00:00\",inplace=True)\n",
    "dailyData[[\"datetime\"]] = dailyData[[\"datetime\"]].astype(str)\n",
    "dailyData['hour'] = dailyData.datetime.apply(lambda x : x.split()[1].split(\":\")[0])\n",
    "dailyData[\"weekday\"] = dailyData.datetime.apply(lambda dateString : calendar.day_name[datetime.strptime(dateString.split()[0],\"%Y-%m-%d\").weekday()])\n",
    "\n",
    "# calculate the duration mean of hour-weekday pair\n",
    "hour_weekday_mean = dailyData.groupby([\"hour\",\"weekday\"],sort=True)[\"duration\"].mean()\n",
    "\n",
    "# calculate duration mean in terms of hour\n",
    "hour_mean = dailyData.groupby(\"hour\").mean()['duration']\n",
    "\n",
    "# fill nan with 2019-03-31 00:00:00 in datetime\n",
    "features = features.rename(columns={'pickup_datetime':'datetime'})\n",
    "features['datetime'].fillna(\"2019-03-31 00:00:00\",inplace=True)\n",
    "features[[\"datetime\"]] = features[[\"datetime\"]].astype(str)\n",
    "\n",
    "# Remove the nan from dropoff_zone and pickup_zone\n",
    "features['dropoff_zone'].fillna(\"NV\",inplace=True)\n",
    "features['pickup_zone'].fillna(\"NV\",inplace=True)\n",
    "\n",
    "# Fill nan with specific number\n",
    "features['passenger_count'].fillna(1,inplace=True)\n",
    "features['VendorID'].fillna(2,inplace=True)\n",
    "\n",
    "# get weekday\n",
    "features['year'] = features.datetime.apply(lambda x : x.split()[0].split(\"-\")[0])\n",
    "features['month'] = features.datetime.apply(lambda x : x.split()[0].split(\"-\")[1])\n",
    "features['day'] = features.datetime.apply(lambda x : x.split()[0].split(\"-\")[2])\n",
    "features['hour'] = features.datetime.apply(lambda x : x.split()[1].split(\":\")[0])\n",
    "features[\"weekday\"] = features.datetime.apply(lambda dateString : calendar.day_name[datetime.strptime(dateString.split()[0],\"%Y-%m-%d\").weekday()])\n",
    "\n",
    "# combine pickup_zone & dropoff_zone, hour & weekkday\n",
    "# features['zone'] = features.apply(lambda x: str(x['pickup_zone'])+\"-\"+str(x['dropoff_zone']),axis=1)\n",
    "features['hour_weekday'] = features.apply(lambda x: str(x['hour'])+\"-\"+str(x['weekday']),axis=1)\n",
    "features['borough_path'] = features.apply(lambda x: str(x['pickup_borough'])+\"-\"+str(x['dropoff_borough']),axis=1)\n",
    "\n",
    "# calculate the duration mean of hour-weekday pair\n",
    "weekday_order = {\"Friday\":0,\"Monday\":1,\"Saturday\":2,\"Sunday\":3,\"Thursday\":4,\"Tuesday\":5,\"Wednesday\":6}\n",
    "features['hour_weekday_mean'] = features.apply(lambda x: hour_weekday_mean[7*int(x[\"hour\"])+weekday_order[x[\"weekday\"]]],axis=1)\n",
    "\n",
    "# calculate duration mean in terms of hour\n",
    "features['hour_mean'] = features.apply(lambda x: hour_mean[int(x['hour'])],axis=1)\n",
    "\n",
    "# calculate log1p(trip_distance)\n",
    "features['trip_distance_log'] = features.apply(lambda x: np.log1p(x['trip_distance']),axis=1)\n",
    "\n",
    "# workday or not\n",
    "features['workday'] = features.apply(lambda x: 1 if x['weekday'] in [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\"] else 0,axis=1)\n",
    "features['same_borough'] = features.apply(lambda x: 1 if x['pickup_borough']==x['dropoff_borough']  else 0,axis=1)\n",
    "# features = features.drop([\"year\",\"hour_weekday\",\"day\",\"datetime\",\"passenger_count\",\"dropoff_zone\",\"pickup_zone\",\"VendorID\",], axis=1)\n",
    "\n",
    "# categoricalFeatureNames = [\"workday\",\"month\",\"hour\",\"weekday\",\"pickup_borough\",\"dropoff_borough\"]\n",
    "# for var in categoricalFeatureNames:\n",
    "#     features[var] = features[var].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID               int64\n",
       "passenger_count        int64\n",
       "trip_distance        float64\n",
       "pickup_borough        object\n",
       "pickup_zone           object\n",
       "dropoff_borough       object\n",
       "dropoff_zone          object\n",
       "year                  object\n",
       "month                 object\n",
       "hour                  object\n",
       "weekday               object\n",
       "hour_weekday          object\n",
       "borough_path          object\n",
       "hour_weekday_mean    float64\n",
       "hour_mean            float64\n",
       "trip_distance_log    float64\n",
       "workday                int64\n",
       "same_borough           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop([\"day\",\"datetime\",], axis=1)\n",
    "features.VendorID = features.VendorID.astype(int)\n",
    "features.passenger_count = features.passenger_count.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                 int64\n",
       "passenger_count          int64\n",
       "trip_distance          float64\n",
       "hour_weekday_mean      float64\n",
       "hour_mean              float64\n",
       "trip_distance_log      float64\n",
       "workday                  int64\n",
       "same_borough             int64\n",
       "pickup_borough_int       int64\n",
       "pickup_zone_int          int64\n",
       "dropoff_borough_int      int64\n",
       "dropoff_zone_int         int64\n",
       "year_int                 int64\n",
       "month_int                int64\n",
       "hour_int                 int64\n",
       "weekday_int              int64\n",
       "hour_weekday_int         int64\n",
       "borough_path_int         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################数字型数据列偏度校正-【开始】#######################\n",
    "#使用skew()方法，计算所有整型和浮点型数据列中，数据分布的偏度（skewness）。\n",
    "#偏度是统计数据分布偏斜方向和程度的度量，是统计数据分布非对称程度的数字特征。亦称偏态、偏态系数。\n",
    "numeric_dtypes = ['float64']\n",
    "numerics2 = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "#以0.5作为基准，统计偏度超过此数值的高偏度分布数据列，获取这些数据列的index。\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "#对高偏度数据进行处理，将其转化为正态分布。\n",
    "#Box和Cox提出的变换可以使线性回归模型满足线性性、独立性、方差齐次以及正态性的同时，又不丢失信息。\n",
    "for i in skew_index:\n",
    "    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))#这是boxcox1p的使用方法，参数的具体意义暂时不解释\n",
    "######################数字型数据列偏度校正-【结束】#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.iloc[:len(y), :]\t#y是列向量，存储了训练数据中的房价列信息。截取后得到的X阵的维度是len(y)*(final_features的列数)。\n",
    "X_sub = features.iloc[len(y):, :]#使用len命令，求矩阵X的长度，得到的是矩阵对象的长度，即有矩阵中有多少列，而不是每列上有多少行。\n",
    "outliers = [273591, 274024, 275423, 79323, 237758]\n",
    "X = X.drop(X.index[outliers])#因为X阵是经过对特征矩阵进行类似“坐标投影”操作后得到的，列向量y中的行号对应着X阵中的列号。\n",
    "y = y.drop(y.index[outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a31e3be50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X.trip_distance_log,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit = []#用来记录产生过拟合的数据列的序号\n",
    "for i in X.columns:#遍历截取后特征矩阵的每一列\n",
    "    counts = X[i].value_counts()#使用.value_counts()方法，查看在X矩阵的第i列中，不同的取值分别出现了多少次，默认按次数最高到最低做降序排列。返回一个df。\n",
    "    zeros = counts.iloc[0]#通过行号索引行数据，取出counts列中第一个元素，即出现次数最多的取值到底是出现了多少次，存入zeros\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "#判断某一列是否将产生过拟合的条件：\n",
    "#截取后的特征矩阵有len(X)列，如果某一列中的某个值出现的次数除以特征矩阵的列数超过99.94%，即其几乎在被投影的各个维度上都有着同样的取值，并不具有“主成分”的性质，则记为过拟合列。\n",
    "        overfit.append(i)\n",
    "overfit = list(overfit)\n",
    "#overfit.append('MSZoning_C (all)')#这条语句有用吗？是要把训练数据特征矩阵X中的列标签为'MSZoning_C (all)'的列也删除吗？但是训练数据中并没有任何一个列标签名称为MSZoning_C (all)。\n",
    "X = X.drop(overfit, axis=1)#.copy()#删除截取后特征矩阵X中的过拟合列。因为drop并不影响原数据，所以使用copy。直接覆值应该也可以。\n",
    "X_sub = X_sub.drop(overfit, axis=1)#.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276065, 18)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79393, 18)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征处理已经完成。开始对训练数据进行机器学习 2020-05-03 01:19:56.878033\n"
     ]
    }
   ],
   "source": [
    "##############################################################机器学习-【开始】###################################################################################\n",
    "print('特征处理已经完成。开始对训练数据进行机器学习', datetime.now())\n",
    "\n",
    "#设置k折交叉验证的参数。\n",
    "kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "#定义均方根对数误差（Root Mean Squared Logarithmic Error ，RMSLE）\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "\n",
    "#创建模型评分函数，根据不同模型的表现打分\n",
    "#cv表示Cross-validation,交叉验证的意思。\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############个体机器学习模型的创建（即模型声明和参数设置）-【开始】############\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "#定义ridge岭回归模型（使用二范数作为正则化项。不论是使用一范数还是二范数，正则化项的引入均是为了降低过拟合风险。）\n",
    "#注：正则化项如果使用二范数，那么对于任何需要寻优的参数值，在寻优终止时，它都无法将某些参数值变为严格的0，尽管某些参数估计值变得非常小以至于可以忽略。即使用二范数会保留变量的所有信息，不会进行类似PCA的变量凸显。\n",
    "#注：正则化项如果使用一范数，它比L2范数更易于获得“稀疏(sparse)”解，即它的求解结果会有更多的零分量。\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "\n",
    "#定义LASSO收缩模型（使用L1范数作为正则化项）（由于对目标函数的求解结果中将得到很多的零分量，它也被称为收缩模型。）\n",
    "#注：正则化项如果使用二范数，那么对于任何需要寻优的参数值，在寻优终止时，它都无法将某些参数值变为严格的0，尽管某些参数估计值变得非常小以至于可以忽略。即使用二范数会保留变量的所有信息，不会进行类似PCA的变量凸显。\n",
    "#注：正则化项如果使用一范数，它比L2范数更易于获得“稀疏(sparse)”解，即它的求解结果会有更多的零分量。\t\t\t\t\t\t\t\t\t\t\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "\n",
    "#定义elastic net弹性网络模型（弹性网络实际上是结合了岭回归和lasso的特点，同时使用了L1和L2作为正则化项。）\t\t\t\t\t\t\t\t\t\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))\n",
    "\n",
    "#定义GB梯度提升模型（展开到一阶导数）\t\t\t\t\t\t\t\t\t\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)                             \n",
    "\n",
    "#定义lightgbm模型\t\t\t\t\t\t\t\t\t\n",
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       #min_data_in_leaf=2,\n",
    "                                       #min_sum_hessian_in_leaf=11\n",
    "                                       )\n",
    "\n",
    "#定义xgboost模型（展开到二阶导数）                                      \n",
    "# xgboost = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n",
    "#                                      max_depth=3, min_child_weight=0,\n",
    "#                                      gamma=0, subsample=0.7,\n",
    "#                                      colsample_bytree=0.7,\n",
    "#                                      objective='reg:linear', nthread=-1,\n",
    "#                                      scale_pos_weight=1, seed=27,\n",
    "#                                      reg_alpha=0.00006)\n",
    "#############个体机器学习模型的创建（即模型声明和参数设置）-【结束】############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行交叉验证，计算不同模型的得分TEST score on CV\n",
      "lightgbm轻梯度提升模型的得分: 0.3190 (0.0012)\n",
      " 2020-05-02 10:22:24.299037\n",
      "gbr梯度提升回归模型的得分: 0.3014 (0.0011)\n",
      " 2020-05-02 11:11:51.337355\n",
      "[11:11:53] WARNING: /private/var/folders/ps/ksq1f2ys3yb_lz7s32c1g8280000gn/T/pip-install-zp3recm6/xgboost/xgboost/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:25:55] WARNING: /private/var/folders/ps/ksq1f2ys3yb_lz7s32c1g8280000gn/T/pip-install-zp3recm6/xgboost/xgboost/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:37:27] WARNING: /private/var/folders/ps/ksq1f2ys3yb_lz7s32c1g8280000gn/T/pip-install-zp3recm6/xgboost/xgboost/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:44:02] WARNING: /private/var/folders/ps/ksq1f2ys3yb_lz7s32c1g8280000gn/T/pip-install-zp3recm6/xgboost/xgboost/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:53:30] WARNING: /private/var/folders/ps/ksq1f2ys3yb_lz7s32c1g8280000gn/T/pip-install-zp3recm6/xgboost/xgboost/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "xgboost模型的得分: 0.3138 (0.0011)\n",
      " 2020-05-02 17:18:43.542687\n"
     ]
    }
   ],
   "source": [
    "###########################集成多个个体学习器-【开始】##########################\n",
    "###！！！！！！！！！！！！\n",
    "###！！！！！！！！！！！！\n",
    "###！！！！！！！！！！！！\n",
    "###！！！！！！！！！！！！\n",
    "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)#regressors=(...)中并没有纳入前面的svr模型\n",
    "###########################集成多个个体学习器-【结束】##########################                             \n",
    "\n",
    "############################进行交叉验证打分-【开始】###########################\n",
    "#进行交叉验证，并对不同模型的表现打分\n",
    "#（由于是交叉验证，将使用不同的数据集对同一模型进行评分，故每个模型对应一个得分序列。展示模型得分序列的平均分、标准差）\n",
    "print('进行交叉验证，计算不同模型的得分TEST score on CV')\n",
    "\n",
    "#打印二范数rideg岭回归模型的得分\n",
    "score = cv_rmse(ridge)\n",
    "print(\"二范数rideg岭回归模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印一范数LASSO收缩模型的得分\n",
    "score = cv_rmse(lasso)\n",
    "print(\"一范数LASSO收缩模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印elastic net弹性网络模型的得分\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"elastic net弹性网络模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "# #打印SVR支持向量机模型的得分\n",
    "# score = cv_rmse(svr)\n",
    "# print(\"SVR支持向量机模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印lightgbm轻梯度提升模型的得分\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"lightgbm轻梯度提升模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印gbr梯度提升回归模型的得分\n",
    "score = cv_rmse(gbr)\n",
    "print(\"gbr梯度提升回归模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印xgboost模型的得分\n",
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "############################进行交叉验证打分-【结束】###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行交叉验证，计算不同模型的得分TEST score on CV<br>\n",
    "二范数rideg岭回归模型的得分: 0.3205 (0.0012)<br>\n",
    " 2020-05-02 00:15:30.857070<br>\n",
    "一范数LASSO收缩模型的得分: 0.3208 (0.0012)<br>\n",
    " 2020-05-02 01:33:14.781908<br>\n",
    "elastic net弹性网络模型的得分: 0.3212 (0.0012)<br>\n",
    " 2020-05-02 02:23:17.939383<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行模型参数训练 START Fit\n",
      "2020-05-02 17:18:43.563359 对stack_gen集成器模型进行参数训练\n",
      "[21:28:23] WARNING: /private/var/folders/ps/ksq1f2ys3yb_lz7s32c1g8280000gn/T/pip-install-zp3recm6/xgboost/xgboost/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:37:46] WARNING: /private/var/folders/ps/ksq1f2ys3yb_lz7s32c1g8280000gn/T/pip-install-zp3recm6/xgboost/xgboost/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:51:41] WARNING: /private/var/folders/ps/ksq1f2ys3yb_lz7s32c1g8280000gn/T/pip-install-zp3recm6/xgboost/xgboost/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9b319fa34390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'对stack_gen集成器模型进行参数训练'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstack_gen_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'对elasticnet弹性网络模型进行参数训练'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/mlxtend/regressor/stacking_cv_regression.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, sample_weight)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 fit_params=fit_params, pre_dispatch=self.pre_dispatch)\n\u001b[0;32m--> 191\u001b[0;31m                     for regr in self.regr_])\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# save meta-features for training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/mlxtend/regressor/stacking_cv_regression.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 fit_params=fit_params, pre_dispatch=self.pre_dispatch)\n\u001b[0;32m--> 191\u001b[0;31m                     for regr in self.regr_])\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# save meta-features for training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    753\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    754\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 755\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    547\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    207\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1247\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1248\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1250\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#########使用训练数据特征矩阵作为输入，训练数据对数处理后的预测房价作为输出，进行各个模型的训练-【开始】#########\n",
    "#开始集合所有模型，使用stacking方法\n",
    "print('进行模型参数训练 START Fit')\n",
    "\n",
    "print(datetime.now(), '对stack_gen集成器模型进行参数训练')\n",
    "stack_gen_model = stack_gen.fit(np.array(X), np.array(y))\n",
    "\n",
    "print(datetime.now(), '对elasticnet弹性网络模型进行参数训练')\n",
    "elastic_model_full_data = elasticnet.fit(X, y)\n",
    "\n",
    "print(datetime.now(), '对一范数lasso收缩模型进行参数训练')\n",
    "lasso_model_full_data = lasso.fit(X, y)\n",
    "\n",
    "print(datetime.now(), '对二范数ridge岭回归模型进行参数训练')\n",
    "ridge_model_full_data = ridge.fit(X, y)\n",
    "\n",
    "print(datetime.now(), '对lightgbm轻梯度提升模型进行参数训练')\n",
    "lgb_model_full_data = lightgbm.fit(X, y)\n",
    "\n",
    "print(datetime.now(), '对GradientBoosting梯度提升模型进行参数训练')\n",
    "gbr_model_full_data = gbr.fit(X, y)\n",
    "\n",
    "print(datetime.now(), '对xgboost二阶梯度提升模型进行参数训练')\n",
    "xgb_model_full_data = xgboost.fit(X, y)\n",
    "\n",
    "\n",
    "#########使用训练数据特征矩阵作为输入，训练数据对数处理后的预测房价作为输出，进行各个模型的训练-【结束】#########\n",
    "\n",
    "############################进行交叉验证打分-【结束】###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########定义个体学习器的预测值融合函数，检测预测值融合策略的效果-【开始】#######\n",
    "#综合多个模型产生的预测值，作为多模型组合学习器的预测值\n",
    "def blend_models_predict(X):\n",
    "    return ((0.05 * elastic_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lasso_model_full_data.predict(X)) + \\\n",
    "            (0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "            (0.2 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            (0.35 * stack_gen_model.predict(np.array(X))))\n",
    "\n",
    "#打印在上述模型配比下，多模型组合学习器的均方根对数误差（Root Mean Squared Logarithmic Error ，RMSLE）\n",
    "#使用训练数据对创造的模型进行k折交叉验证，以训练创造出的模型的参数配置。交叉验证训练过程结束后，将得到模型的参数配置。使用得出的参数配置下，在全体训练数据上进行验证，验证模型对全体训练数据重构的误差。\n",
    "print('融合后的训练模型对原数据重构时的均方根对数误差RMSLE score on train data:')\n",
    "########定义个体学习器的预测值融合函数，检测预测值融合策略的效果-【结束】#######\n",
    "\n",
    "########将测试集的特征矩阵作为输入，传入训练好的模型，得出的输出写入.csv文件的第2列-【开始】########\n",
    "submission = pd.read_csv(\"submission.csv\")\n",
    "#函数注释：.iloc[:,1]是基于索引位来选取数据集，[索引1:索引2]，左闭右开。\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(X_sub)))\n",
    "########将测试集的特征矩阵作为输入，传入训练好的模型，得出的输出写入.csv文件的第2列-【结束】########\n",
    "q1 = submission['duration'].quantile(0.005)\n",
    "q2 = submission['duration'].quantile(0.995)\n",
    "submission['duration'] = submission['duration'].apply(lambda x: x if x > q1 else x*0.77)\n",
    "submission['duration'] = submission['duration'].apply(lambda x: x if x < q2 else x*1.1)\n",
    "submission.duration=submission.duration.astype(int)\n",
    "submission.head(2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
